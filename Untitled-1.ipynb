{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import loguniform\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(file_name, isTrain):\n",
    "    train = pd.read_csv(file_name)\n",
    "    if isTrain:\n",
    "        # link in present only in train dataset\n",
    "        train = train.drop(['link'], axis=1)\n",
    "    fields = ['publication_date', 'latitude', 'longitude','category', 'floor', 'area', 'kupcha', 'rooms', 'repairs', 'hypothec', 'location attributes']\n",
    "    if isTrain:\n",
    "        fields.append('price')\n",
    "    train = train[fields]\n",
    "\n",
    "    # clean data to make it readable for the algorithm\n",
    "    train.replace('var', True, inplace=True)\n",
    "    train.replace('yoxdur', False, inplace=True)\n",
    "    train.replace(np.nan, False, inplace=True)\n",
    "    train.replace({'m²': ''}, regex=True, inplace=True)\n",
    "    train.replace('Yeni tikili', True, inplace=True)\n",
    "    train.replace('Köhnə tikili', False, inplace=True)\n",
    "    train = train.astype({\"area\": float})\n",
    "    currentFloors = []\n",
    "    maxFloors = []\n",
    "    for floor in train['floor'].array:\n",
    "        floors = floor.split(' / ')\n",
    "        currentFloors.append(floors[0])\n",
    "        maxFloors.append(floors[1])\n",
    "    train[\"current_floor\"] = currentFloors\n",
    "    train[\"max_floor\"] = maxFloors\n",
    "    \n",
    "    train = train.astype({\"current_floor\": int})\n",
    "    train = train.astype({\"max_floor\": int})\n",
    "    del train['floor']\n",
    "    \n",
    "    day = []\n",
    "    month = []\n",
    "    for index in range(0, len(train['publication_date'].array)):\n",
    "        element = train['publication_date'].array[index]\n",
    "        values = element.split(' ')\n",
    "        if values[1] == 'Yanvar':\n",
    "            month.append(1)\n",
    "        elif values[1] == 'Dekabr':\n",
    "            month.append(0)\n",
    "        day.append(values[0]) \n",
    "    del train['publication_date']\n",
    "    train['day'] = day\n",
    "    train['month'] = month\n",
    "\n",
    "    return train\n",
    "train = process('modified_train_binaaz.csv', True)\n",
    "tags = train[\"location attributes\"]\n",
    "clean_tags = tags.str.strip('[]\\'').str.split('\\', \\'')\n",
    "a = clean_tags.apply(pd.Series)\n",
    "b = a.stack()\n",
    "c = pd.get_dummies(b)\n",
    "d = c.groupby(level=0).sum()\n",
    "\n",
    "train = train.join(d)\n",
    "train = train.drop(['location attributes'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = process('test_binaaz_updated.csv', False)\n",
    "tags = test[\"location attributes\"]\n",
    "test_clean_tags = tags.str.strip('[]\\'').str.split('\\', \\'')\n",
    "a = test_clean_tags.apply(pd.Series)\n",
    "b = a.stack()\n",
    "c = pd.get_dummies(b)\n",
    "d = c.groupby(level=0).sum()\n",
    "\n",
    "tags = set()\n",
    "for ls in clean_tags:\n",
    "   for tag in ls:\n",
    "    tags.add(tag)\n",
    "\n",
    "test_tags = set()\n",
    "for ls in test_clean_tags:\n",
    "   for tag in ls:\n",
    "    test_tags.add(tag)\n",
    "\n",
    "to_add = tags.difference(test_tags)\n",
    "empty = []\n",
    "for i in range(0, len(d.index)):\n",
    "    empty.append(0)\n",
    "\n",
    "map = {'price': empty}\n",
    "for add in to_add:\n",
    "    map[add] = empty\n",
    "\n",
    "additional = pd.DataFrame(map)\n",
    "\n",
    "test = test.join(d)\n",
    "test = test.join(additional)\n",
    "to_drop = ['location attributes'] + list(test_tags.difference(tags))\n",
    "test = test.drop(to_drop, axis=1)\n",
    "\n",
    "target = 'price'\n",
    "columns = train.columns.tolist()\n",
    "columns = [c for c in columns if c not in [\"price\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>mean_test_error</th>\n",
       "      <th>std_test_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1300</td>\n",
       "      <td>6.520662e+09</td>\n",
       "      <td>2.454553e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1100</td>\n",
       "      <td>6.653452e+09</td>\n",
       "      <td>2.479403e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1500</td>\n",
       "      <td>6.657138e+09</td>\n",
       "      <td>2.535673e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>900</td>\n",
       "      <td>6.828559e+09</td>\n",
       "      <td>2.557727e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>700</td>\n",
       "      <td>6.957095e+09</td>\n",
       "      <td>2.539434e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500</td>\n",
       "      <td>7.181199e+09</td>\n",
       "      <td>2.618706e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300</td>\n",
       "      <td>7.616456e+09</td>\n",
       "      <td>2.559157e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>9.092941e+09</td>\n",
       "      <td>2.504205e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_n_estimators  mean_test_error  std_test_error\n",
       "6               1300     6.520662e+09    2.454553e+09\n",
       "5               1100     6.653452e+09    2.479403e+09\n",
       "7               1500     6.657138e+09    2.535673e+09\n",
       "4                900     6.828559e+09    2.557727e+09\n",
       "3                700     6.957095e+09    2.539434e+09\n",
       "2                500     7.181199e+09    2.618706e+09\n",
       "1                300     7.616456e+09    2.559157e+09\n",
       "0                100     9.092941e+09    2.504205e+09"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_distributions = {\n",
    "    'n_estimators': range(100, 1501, 200),\n",
    "    # 2. 'max_depth': range(5, 71, 5),\n",
    "    # 2. 'min_samples_split': range(100, 1101, 200),\n",
    "    # 3. 'max_features': range(7, 20, 2),\n",
    "    # 4. 'subsample': [0.6,0.7,0.75,0.8,0.85,0.9]\n",
    "}\n",
    "\n",
    "\n",
    "gbr = GradientBoostingRegressor(learning_rate = 0.1, min_samples_split=180, min_samples_leaf = 50,\n",
    "                                 max_features='sqrt', subsample=0.8, max_depth= 8)\n",
    "search_cv = GridSearchCV(estimator=gbr, \n",
    "                   param_grid=param_distributions,\n",
    "                   scoring = 'neg_mean_squared_error', \n",
    "                   verbose=3,\n",
    "                   error_score='raise',\n",
    "                   n_jobs=-1)\n",
    "\n",
    "search_cv.fit(train[columns], train[target])\n",
    "\n",
    "columns = [f\"param_{name}\" for name in param_distributions.keys()]\n",
    "columns += [\"mean_test_error\", \"std_test_error\"]\n",
    "cv_results = pd.DataFrame(search_cv.cv_results_)\n",
    "cv_results[\"mean_test_error\"] = -cv_results[\"mean_test_score\"]\n",
    "cv_results[\"std_test_error\"] = cv_results[\"std_test_score\"]\n",
    "cv_results[columns].sort_values(by=\"mean_test_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed error: 72165.93501543833\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clf = GradientBoostingRegressor(learning_rate=0.1, n_estimators = 900, max_leaf_nodes= 50, min_samples_split=25, subsample=0.8, random_state= 0, max_features=17, max_depth=50)\n",
    "training = train.sample(frac=0.7, random_state=5)\n",
    "test = train.loc[~train.index.isin(training.index)]\n",
    "clf.fit(training[columns], training[target])\n",
    "clf = clf.predict(test[columns])\n",
    "# Compute error between our test predictions and the actual values.\n",
    "lin_mse = mean_squared_error(clf, test[target], squared=False)\n",
    "print(\"Computed error:\", lin_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to save the result\n",
    "result = pd.DataFrame(clf)\n",
    "result.to_csv(\"result.csv\", header=['price'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31e71d7ed0fa0b4c5d8ce44b530b41ec61e7cc3af5332ca9786b8048d514a256"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
